---
title: "Cerdeira_Diiuorio_TP4"
output: pdf_document
date: "2025-05-28"

---

```{r, echo = FALSE}
set.seed(1234)
datos_historicos = read.csv("datos_historicos.csv")$play.delay
datos_nueva_version = read.csv("datos_nueva_version.csv")$play.delay

```

## Ejercicio 1
### (A)

```{r, echo = FALSE}
media_muestral <- round(mean(datos_historicos),2)
var_muestral <- round(var(datos_historicos),2)
sd0 <- round(sd(datos_historicos),2)
``` 

La **media muestral** de los datos historicos es **`r media_muestral`**.

La **varianza muestral** de los datos historicos es **`r var_muestral`**.

### (B)

``` {r, echo = FALSE}
hist(datos_historicos, prob = TRUE, breaks=30 ,col = "sandybrown", main = "Histograma de densidad de datos historicos")
curve(dnorm(x, mean = media_muestral, sd = sqrt(var_muestral)), lwd = 2, lty = 2, add = TRUE, col = "black")

```

Los datos parecen distribuirse de forma normal.

## Ejercicio 2



Primero definimos:


* \(\mu_0 \) = media del "play-delay" de la versión anterior = 41.9847 

* \(\sigma_0^2\) = varianza del "play-delay" de la versión anterior = 52.4325




Ahora definimos:

$$ X_i = \text{El "play-delay" del i-ésimo usuario evaluado con la nueva versión. }\space 1\leq i\leq 200  $$



Y contamos con la siguiente distribución de nuestra muestra:

$$ \space X_1, ..., X_{200} \sim \mathcal{N}(\mu, {52.43}) \text{ iid} \\$$

Donde:

$$ \mu = \text{media del ``play-delay'' }   \\$$

```{r, echo = FALSE}

mu_estimado = round(mean(datos_nueva_version),2)

```


Para estimar \(\mu\) vamos calcular la **media muestral** de la muestra con los 200 nuevos usuarios.

La estimación de \(\mu\) es:  

$$ \hat{\mu} = \overline{X} = 42.99 \\$$

## Ejercicio 3

### (A) 



Proponemos las siguientes Hipótesis Nula e Hipótesis Alternativa


$$ H_0: \mu \leq \mu_0\quad vs.\quad H_1: \mu > \mu_0\quad \\$$ 


Es decir,
$$ H_0: \mu \leq 41.98 \quad\text{vs}.\quad  H_1: \mu > 41.98 \\$$


Para simplificar el problema, suponemos:
$$ H_0: \mu = 41.98  \\$$

Esto se puede hacer ya que el caso límite de \(H_0\) es cuando \(\mu\) = 41.9847. Por lo tanto, si puedo rechazar esa \(H_0\) entonces puedo rechazar también todos los valores de 

$$ \mu \leq 41.98 \\$$


Por ende, las hipótesis quedarían así:


$$ H_0: \mu = 41.98 \quad\text{vs}.\quad  H_1: \mu > 41.98 \\$$

**Estadístico:** 


Para hallar el estadístico partimos del estimador de \(\mu\):  

$$ \hat{\mu} = \overline{X} $$
Asumimos distribución de  \(\overline{X}\) bajo  \(H_{0}\):

$$ \overline{X} \sim \mathcal{N}(41.98, \frac{52.43}{200}) \quad \text{bajo } H_0 \\$$

Lo estandarizamos:

$$T=\frac{\overline{X}-41.98}{\sqrt{52.43 / 200}} \sim \mathcal{N}(0, 1) \quad \text{bajo } H_0 \\$$

T es nuestro estadístico. Nos sirve porque es una función de la muestra aleatoria y tiene distribución conocida bajo \(H_0\). 

### (B)

$$ \alpha = 0.05 \\$$



Vamos a rechazar \(H_{0}\) cuando \(\overline{X}>C\) donde C es un número tal que:

$$ \quad \alpha = P(EI) = P(\text{Rechazar } H_0 | H_0  \text{ es V}) = P(\overline{X}>C| H_0 \text{ es V})  \\$$
$$ \implies \text{Queremos C tal que } P(\overline{X}>C|H_0 \text{ es V})=0.05 \\$$

$$ P(\overline{X}>C|H_0 \text{ es V}) = {P(\frac{\overline{X}-41.98}{\sqrt{52.43 / 200}} > \frac{C-41.98}{\sqrt{52.43 / 200}} \space| H_0 \text{ es V })} \\$$



$$ como \quad \frac{\overline{X}-41.98}{\sqrt{52.43 / 200}}  \sim \mathcal{N}(0, 1) \quad \text{bajo } H_0 \\$$

Entonces lo llamamos Z ya que 

$$ Z \sim \mathcal{N}(0, 1) \\$$

Por lo tanto, 


$$ {P(\frac{\overline{X}-41.98}{\sqrt{52.43 / 200}} > \frac{C-41.98}{\sqrt{52.43 / 200}} \space| H_0 \text{ es V })} = P(Z > q) \\$$

donde 

$$ q = \space \frac{C-41.98}{\sqrt{52.43 / 200}}  \\$$


Según la Hipótesis Alternativa, decidimos rechazar \(H_0\) cuando:  

$$  T = \frac{\overline{X}-41.98}{\sqrt{52.43 / 200}} > q \\$$


$$ \text{Queremos }  q \space / P(Z > q) = \alpha = 0.05 \\$$

``` {r}
alpha <- 0.05
q <- qnorm(1-alpha, mean = 0, sd = 1)
```

```{r, echo = FALSE}
media <- 0
desvio <- 1
x <- seq(-4, 4, length = 1000)
y <- dnorm(x, mean = media, sd = desvio)

# Graficamos la curva normal
plot(x, y, type = "l", lwd = 2, col = "orange",
     xlab = "N(0,1)", ylab = "", 
     main = paste("Área =", alpha, "a derecha de q"))

# Sombrear el área correspondiente
x_somb <- seq( q, 4, length = 1000)
y_somb <- dnorm(x_somb, mean = media, sd = desvio)

polygon(c(x_somb, rev(x_somb)), 
        c(y_somb, rep(0, length(y_somb))), 
        col = rgb(1, .5, 0, 0.3), border = NA)

# Línea vertical en q
abline(v = q, col = "orange4", lwd = 2, lty = 2)
text(q, dnorm(q), labels = sprintf("q"), pos = 4, col = "orange4")

```





Entonces, q es un cuantil tal que me deja área \(\alpha\) = 0.05 a derecha o área 1 - \(\alpha\) = 0.95 a izquierda .



$$ \text{Por lo tanto } q = Z_{\alpha} = Z_{0.05} \\$$


Nuestra Región de Rechazo quedaría 

$$ R = \{ T > Z_{0.05}\} \\$$

Por la tabla de una Normal Estándar, podemos ver que 


$$ q = Z_{0.05} = 1.64 \\$$



Como resultado, la Región de Rechazo para este test es:


$$ R = \{ T > 1.64\} \\$$


## Ejercicio 4

### (A)


Para utilizar el test construido, el primer paso es calcular el promedio de los valores de la muestra "datos nueva versión". Una vez calculado, evaluamos nuestro estadístico observado. Si este pertenece en la Región de Rechazo, rechazamos \(H_0\). En el caso de no pertenecer a la región, no confirmamos que \(H_0\) sea verdadera sino que no tenemos la suficiente evidencia para rechazarla.  

Como vimos antes:

$$ \hat{\mu} = \overline{X} =  42.99 \\$$
Ahora, buscamos al estadístico observado de esta muestra. 

$$  T_{obs} = \frac{\overline{X}_{obs}-41.98}{\sqrt{52.43 / 200}} \\$$

$$  T_{obs} = \frac{42.99-41.98}{\sqrt{52.43 / 200}} = 1.97\\$$

```{r, echo = FALSE}

Tobs <- round((42.99 - 41.98) / sqrt(52.43/200), 2)

```

Mi estadístico observado es \(T_{obs}\) = `r Tobs`

Como podemos ver, el estadístico observado pertenece a la región de rechazo. Tenemos suficiente evidencia para rechazar \(H_0\) porque `r Tobs` > 1.64

Con esta evidencia rechazamos la actualización ya que aumenta el "play-delay", es decir, la esperanza del "play-delay" con la versión nueva es mayor a la actual, y es por eso que enviamos el código a revisión. 


### (B)

```{r, echo = FALSE}

alpha_1 <- 0.01
alpha_2 <- 0.1

q1 <- qnorm(1 - alpha_1, mean = 0, sd = 1)
q2 <- qnorm(1 - alpha_2, mean = 0, sd = 1)


```

#### \(\alpha\)=0.01


$$ P(EI) = P(\text{Rechazar } H_0 | H_0 \text{ es V}) = 0.01 \\$$

La Región de Rechazo con \(\alpha\) = 0.01 será:

$$ R = \{T > Z_{\alpha}\} = \{T > Z_{0.01}\} = \{T > 2.33\}  \\$$
El cuantil \(Z_{0.01}\) deja menos área a la derecha que el cuantil \(Z_{0.05}\). Esto implica que el primero está gráficamente a derecha del segundo (\(Z_{0.05}\) < \(Z_{0.01}\)).  


#### \(\alpha\)=0.1

$$ P(EI) = P(\text{Rechazar } H_0 | H_0 \text{ es V}) = 0.1 \\$$
La Región de Rechazo con \(\alpha\) = 0.1 será:

$$ R = \{T > Z_{\alpha}\} = \{T > Z_{0.1}\} = \{T > 1.28\} \\$$

El cuantil \(Z_{0.1}\) deja más área a la derecha que el cuantil \(Z_{0.05}\). Esto implica que el primero está gráficamente a izquierda del segundo (\(Z_{0.1}\) < \(Z_{0.05}\)).  


El \(\alpha\) desplaza el punto de corte para la Región de Rechazo. A mayor \(\alpha\), menor es el punto de corte del cual arranca la Región de Rechazo. Aplicado a este test, a mayor \(\alpha\), mando más seguido actualizaciones a auditar, ya que el estadístico observado puede ser menor para rechazar \(H_0\) y decir que el "play-delay" de la nueva versión es mayor al actual. 



### (C)

Para cada \(\alpha\), calculamos el \(Z_{\alpha}\): el punto que marca el comienzo de la región de rechazo.

$$ R=\{T>Z_{\alpha}\} $$
Si el **T observado (1.97)** es mayor al \(Z_{\alpha}\) para un \(\alpha\) dado, entonces tendremos evidencia suficiente a nivel \(\alpha\) para rechazar \(H_{0}\).


```{r, echo= FALSE}

alfas <- seq(0.01, 0.10, by = 0.01)

z_crit  <- numeric(length(alfas))   # un vector numérico vacío (de ceros) de la misma longitud que 'alfas'
decision <- character(length(alfas)) # un vector de texto (caracteres) vacío

for(i in 1:length(alfas)){
  
  z_crit[i] <- qnorm(1-alfas[i])
  
  if(Tobs >= z_crit[i]){
    decision[i] <- "Rechazo H0"
  } else {
    decision[i] <- "No Rechazo H0"
  }
}

# Armo un data.frame con las tres columnas
tabla <- data.frame(
  alpha    = alfas,
  z_alpha   = round(z_crit, 3),  # redondeo a 3 decimales para que quede prolijo
  decision = decision
)

print(tabla)

```

Se puede ver que para un **\(\alpha\) igual o mayor a 0.03** ya puedo rechazar \(H_{0}\).
Es útil ver estos resultados de forma grafica:


```{r, echo = FALSE}
# plot vacío con ejes y densidad
plot(NA, xlim = c(-4, 4), ylim = c(0, dnorm(0)), 
     xlab = "Valor de Z", ylab = "Densidad", 
     main = "Normal Estándar con cortes y T_obs")

# dibujo la curva de la Normal estándar
curve(dnorm(x), from = -4, to = 4, add = TRUE, 
      col = "orange", lwd = 2)

# --------------------------------------------
# 3) Agrego líneas punteadas para cada z_crítico
# --------------------------------------------
for (zc in z_crit) {
  abline(v = zc, lty = 2, col = "orange", lwd = 1)
}

# --------------------------------------------
# 4) Agrego la línea gruesa para z_obs
# --------------------------------------------
abline(v = Tobs, col = "black", lwd = 2)

# --------------------------------------------
# 5) Agrego leyenda para aclarar
# --------------------------------------------
legend("topleft", 
       legend = c("Normal Estándar", 
                  paste0("T-obs = ", round(Tobs, 3))),
       col    = c("orange", "black"),
       lty    = c(1, 1),
       lwd    = c(2, 2),
       bty    = "n")
```

Estos resultados tienen sentido: cuánto más chico es el nivel de significancia \(\alpha\) más difícil es rechazar \(H_{0}\). 
Esto se puede apreciar en el gráfico: los "Z críticos" (\(Z_{\alpha}\)) de los niveles de significancia más chicos (0.01 y 0.02) son las líneas punteadas a la derecha del T-observado. Esto quiere decir que el valor que observamos no es "tan extremo" cómo para darnos suficiente evidencia que nos permita rechazar \(H_{0}\) en niveles de significancia 0.01 o 0.02.

### (D)

Ahora queremos encontrar el valor minimo de \(\alpha\) para el cuál podriamos rechazar \(H_{0}\) con los datos observados. Del inciso anterior, sabemos que éste valor minimo tiene que estar entre \(\alpha=0.02\) y \(\alpha=0.03\). Vamos a armar un for-loop que vaya probando todos los numeros decimales entre 0.02 y 0.03 con 3 digitos decimales y mostrar los resultados en una tabla:

```{r, echo = FALSE}

alfas2 = seq(0.02,0.03,by=0.001)

z_crit2  <- numeric(length(alfas2))   # un vector numérico vacío (de ceros) de la misma longitud que 'alfas'
decision2 <- character(length(alfas2)) # un vector de texto (caracteres) vacío

for(i in 1:length(alfas2)){
  
  z_crit2[i] <- qnorm(1-alfas2[i])
  
  if(Tobs >= z_crit2[i]){
    decision2[i] <- "Rechazo H0"
  } else {
    decision2[i] <- "No Rechazo H0"
  }
}

# Armo un data.frame con las tres columnas
tabla <- data.frame(
  alpha    = alfas2,
  z_alpha   = round(z_crit2, 3),  # redondeo a 3 decimales para que quede prolijo
  decision = decision2
)

print(tabla)


```


Vemos que el valor minimo de \(\alpha\) para el cuál podemos rechazar \(H_{0}\) es **0.025**. Esto tiene sentido si vemos que el "Z Critico" para éste nivel de significancia (\(Z_{0.025}\)) es igual a nuestro T-observado: **1.96**. Esto no podría ser de otra forma: el nivel mínimo de \(\alpha\) para el cuál puedo rechazar \(H_{0}\) tiene que ser igual al T-observado ya que si fuese más grande no podríamos rechazar \(H_{0}\), y sí fuese más chico no sería el valor mínimo.

0.025 será lo que mida el área a la derecha del T-observado (área sombreada en el gráfico):

```{r, echo = FALSE}
# ——————————————————————————————————————————
# 1) Defino valores esenciales
# ——————————————————————————————————————————

# Valor crítico z (por ej. 1.96)
z_crit3 <- 1.96

# Supongamos que Tobs coincide con z_crit (si no, pon tu valor real)
Tobs <- 1.96

# Calculo la densidad en esos puntos, para cortar la línea justo en la curva
y_z   <- dnorm(z_crit3)
y_obs <- dnorm(Tobs)

# ——————————————————————————————————————————
# 2) Creo el plot vacío y dibujo la curva Normal Estándar
# ——————————————————————————————————————————
plot(
  NA,
  xlim  = c(-4, 4),
  ylim  = c(0, dnorm(0)),
  xlab  = "Valor de Z",
  ylab  = "Densidad",
  main  = "Normal Estándar con Cortes y T_obs"
)

# Agrego la curva de la Normal estándar
curve(dnorm(x), from = -4, to = 4, add = TRUE, col = "orange", lwd = 2)

# ——————————————————————————————————————————
# 3) Sombreo el área a la derecha de z_crit (cola derecha)
# ——————————————————————————————————————————

# 3.1) Genero secuencia desde z_crit hasta el tope superior (4)
xs <- seq(z_crit3, 4, length.out = 200)
ys <- dnorm(xs)

# 3.2) Dibujo el polígono que cubre esa región
polygon(
  x   = c(z_crit3, xs, 4),
  y   = c(0, ys, 0),
  col = "lightgray",
  border = NA
)

# ——————————————————————————————————————————
# 4) Dibujo las líneas verticales cortadas en la curva
# ——————————————————————————————————————————

# Si z_crit == Tobs y querés dejar claro que ambas coinciden,
# desplazamos un poquito cada línea en x (0.015 a cada lado), para que se noten las dos.
# Si Tobs fuera distinto a z_crit, podés quitar el desplazamiento y usar los valores exactos.

# 4.1) Línea roja punteada (valor crítico), pero le resto 0.015 para que no se superponga al negro
segments(
  x0 = z_crit3 - 0.015, y0 = 0,
  x1 = z_crit3 - 0.015, y1 = y_z,
  col = "red",
  lty = 2,
  lwd = 2
)

# 4.2) Línea negra gruesa (T_obs), le sumo 0.015 para que se vea al lado
segments(
  x0 = Tobs + 0.015, y0 = 0,
  x1 = Tobs + 0.015, y1 = y_obs,
  col = "black",
  lwd = 2
)

# ——————————————————————————————————————————
# 5) Leyenda para aclarar qué representa cada cosa
# ——————————————————————————————————————————
legend(
  "topleft",
  legend = c(
    "Normal Estándar",
    paste0("Zona crítica (z = ", z_crit3, ")"),
    paste0("T_obs = ", round(Tobs, 3))
  ),
  col  = c("orange", "red", "black"),
  lty  = c(1, 2, 1),
  lwd  = c(2, 2, 2),
  bty  = "n"
)
```

Es muy importante notar que el área sombreada es el p-valor. Esto tiene sentido si recordamos que el p-valor es la "probabilidad de observar valores iguales o más extremos a lo observados (en direccion a \(H_{1}\)), asumiendo que \(H_{0}\) es verdadera". Gráficamente, el p-valor es el área a derecha del T-obs (en éste caso dónde \(H_{1}: \mu > \mu_{0}\)), en otros casos podria ser el área a la izquierda, o el área en ambos extremos).

Entonces, podemos ver que existe otra manera de pensar al p-valor: "el p-valor es el nivel de significancia del \(\alpha\) mínimo, para el cual puedo rechazar \(H_{0}\) con los datos observados".

## Ejercicio 5

### (A)

En este ejercicio vamos a **simular** una muestra de tamaño \(n = 200\) asumiendo que la hipótesis nula \(H_{0}: \mu = \mu_{0}\) es verdadera, es decir, que la nueva versión **no** modificó la media de Play‐Delay con respecto a los datos históricos. 

Los datos de nuestra muestra tendrán la siguiente distribución:

$$ X_{1},...,X_{200} \sim N(41.98, 52.48)$$
Simulamos la muestra en R:
```{r}
set.seed(1234)
muestra_sim <- rnorm(200, mean=media_muestral, sd= sd0)
```

Calculamos la media muestral:
```{r}
xbar_sim = mean(muestra_sim)
print(xbar_sim)
```

$$\overline{X}=41.56$$
Calculamos el T-Observado:
```{r}
Tobs_sim <- (xbar_sim - media_muestral) / (sd0/sqrt(200))
print(Tobs_sim)
```


$$ T = \frac{41.56-41.98}{\sqrt{52.43/200}}=-0.81$$

En el punto 3.b vimos que la región de rechazo para éste test con un nivel \(\alpha = 0.05\) es:
$$R=\{T>1.64\}$$

Entonces, cómo el T-observado **(-0.81)** es menor que 1.64, **NO tenemos evidencia suficiente para rechazar \(H_{0}\)** con los datos observados.

Esta es la decisión correcta ya que estamos asumiendo que \(H_{0}\) es verdadera. Si, por casualidad, el T-Observado hubiera sido mayor que 1.64, habríamos cometido un **Error de Tipo 1** al rechazar \(H_{0}\).


### (B)

Ahora vamos a repetir el procedimiento anterior **10000 veces**. Vamos a calcular la proporcion de veces que no rechazo \(H_{0}\) y la proporcion de veces que sí lo rechazo (proporcion de veces que cometo un Error de Tipo 1).

Como el test que estamos usando tiene un nivel \(\alpha = 0.05\), esperamos equivocarnos (rechazar \(H_{0}\)) sólo el **5%** de las veces y acertar el **95%** de las veces.

Armamos la simulacion con R e imprimimos los resultados:
```{r, echo = FALSE}

set.seed(1234)

R <- 10000
rejections <- numeric(R)  # vector para guardar 1 si rechazo, 0 si no rechazo
z_alpha <- qnorm(1 - 0.05) 

for (i in 1:R) {
  # 1) Simulo n=200 observaciones bajo H0
  muestra_i <- rnorm(200, mean = media_muestral, sd = sd0 )
  
  # 2) Calculo Z
  xbar_i <- mean(muestra_i)
  Z_i    <- (xbar_i - media_muestral) / (sd0 / sqrt(200))
  
  # 3) Registro si rechazo (1) o no rechazo ()
  rejections[i] <- as.numeric(Z_i > z_alpha)
}

# Proporción de rechazos (error tipo I empírico) 
porc_rechazo_emp <- mean(rejections) * 100    # en %
porc_no_rechazo  <- 100 - porc_rechazo_emp    # proporción de decisión correcta, en %

cat("De", R, "simulaciones:\n")
cat("  • Porcentaje de veces que RECHAZO H0:", round(porc_rechazo_emp, 2), "%\n")
cat("  • Porcentaje de veces que NO RECHAZO H0:", round(porc_no_rechazo, 2), "%\n")
```


Vemos que los resultados que obtuvimos son lo que esperabamos: nos equivocamos casi un 5% porciento de las veces y acertamos el 95% de las veces.

### (C)

El nivel de significancia \(\alpha\) es la probabilidad de cometer un Error de Tipo 1. Es decir, \(\alpha\) se define como:

$$\alpha=P(\text{Rechazar }H_{0} \space | \space H_0 \text{ Verdadera})$$
Al construir un test de hipótesis, uno de los pasos fundamentales es establecer un nivel de significancia \(\alpha\), que debe elegirse en función del contexto del problema. Este nivel representa la probabilidad máxima tolerada de cometer un Error de Tipo 1, es decir, de rechazar la hipótesis nula \(H_0\) cuando en realidad es verdadera. Un valor de \(\alpha\) más bajo implica que somos más conservadores: disminuye la chance de falsos positivos, pero al mismo tiempo aumenta la dificultad para rechazar \(H_0\), lo cual puede reducir el poder del test.

En nuestro caso particular, estamos asumiendo que \(H_0\) es verdadera: es decir, la nueva versión de la plataforma no modificó el valor promedio del Play‐Delay. Por lo tanto, si el test rechaza \(H_0\) bajo esta suposición, estaríamos cometiendo un Error de Tipo 1.

El test que usamos fue diseñado con un nivel de significancia \(\alpha\) = 0.05, lo cual significa que, en promedio, esperamos que el 5% de los tests conduzcan a un rechazo incorrecto de \(H_0\) cuando esta es cierta (que es lo que observamos en el punto anterior).


## Ejercicio 6

### (A)

Si asumimos que \(H_{0}\) es verdadera, podemos calcular la probabilidad de observar un resultado cómo el observado o más extremo midiendo el área a la derecha del T-observado.

```{r, echo = FALSE}
# ——————————————————————————————————————————
# 1) Defino valores esenciales
# ——————————————————————————————————————————

# Valor crítico z (por ej. 1.96)
z_crit3 <- 1.96

# Supongamos que Tobs coincide con z_crit (si no, pon tu valor real)
Tobs <- 1.96

# Calculo la densidad en esos puntos, para cortar la línea justo en la curva
y_z   <- dnorm(z_crit3)
y_obs <- dnorm(Tobs)

# ——————————————————————————————————————————
# 2) Creo el plot vacío y dibujo la curva Normal Estándar
# ——————————————————————————————————————————
plot(
  NA,
  xlim  = c(-4, 4),
  ylim  = c(0, dnorm(0)),
  xlab  = "Valor de Z",
  ylab  = "Densidad",
  main  = "Normal Estándar con Cortes y T_obs"
)

# Agrego la curva de la Normal estándar
curve(dnorm(x), from = -4, to = 4, add = TRUE, col = "orange", lwd = 2)


# 3.1) Genero secuencia desde z_crit hasta el tope superior (4)
xs <- seq(z_crit3, 4, length.out = 200)
ys <- dnorm(xs)

# 3.2) Dibujo el polígono que cubre esa región
polygon(
  x   = c(z_crit3, xs, 4),
  y   = c(0, ys, 0),
  col = "lightgray",
  border = NA
)

# 4.2) Línea negra gruesa (T_obs), le sumo 0.015 para que se vea al lado
segments(
  x0 = Tobs + 0.015, y0 = 0,
  x1 = Tobs + 0.015, y1 = y_obs,
  col = "black",
  lwd = 2
)

legend(
  "topleft",
  legend = c(
    "Normal Estándar",
    paste0("T_obs = ", round(Tobs, 3))
  ),
  col  = c("orange", "black"),
  lty  = c(1, 2, 1),
  lwd  = c(2, 2, 2),
  bty  = "n"
)
```

```{r}
p_valor <- 1 - pnorm(1.96)
print(p_valor)
```

$$\text{p-valor} = 0.25$$

### (B)

Vemos que el p-valor que calculamos es el mismo que habiamos obtenido en el punto 4.d. Como explicamos en ése punto, esto se debe a que el p-valor es el minimo nivel de significancia \(\alpha\) para el que rechazamos \(H_{0}\) con los datos observados.


### Ejercicio 7

### (A)

\(H_0\): "Los datos provienen de una distribución normal".

\(H_1\): "Los datos *no* provienen de una distribución normal".

$$
\begin{array}{c}
H_0 : X_i \sim \mathcal{N}(\mu, \sigma^2)\quad \forall\space i \space : \space 1 \leq i \leq 200 \\
vs. \\
H_1: X_i \nsim \mathcal{N}(\mu, \sigma^2) \quad \text{para al menos un } i
\end{array}
$$  

### (B)

```{r}
print(shapiro.test(datos_historicos))


print(shapiro.test(datos_nueva_version))

```

$$\\$$
Como no se especifica el valor de \(\alpha\) para estos test, se asume que \(\alpha\) = 0.05.


* Si el p-valor \(< 0.05 \implies\) Rechazo \(H_0\) \(\implies\) los datos no son normales.

* Si el p-valor \(\geq 0.05 \implies\) No rechazo \(H_0\) \(\implies\) los datos son compatibles con una normal.


El p-valor en los datos históricos es 0.6934.<


El p-valor en los datos de la nueva versión es 0.867.



En ambos casos el p-valor \(\geq \alpha = 0.05\). Por lo tanto no rechazo \(H_0\) ni para los datos históricos ni para los datos de la nueva versión. Ambos datos son compatibles con una normal. 

